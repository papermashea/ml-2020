{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/Users/smolloy/Dev/parsons/ml-2020_data/toxiccomments_train.csv'\n",
    "toxic_data = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 8 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n"
     ]
    }
   ],
   "source": [
    "print(\"toxic_data is:\", type(toxic_data))\n",
    "print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "print(\"the data types for each of the columns in toxic_data:\")\n",
    "print(toxic_data.dtypes, \"\\n\")\n",
    "print(\"the first 10 rows in toxic_data:\")\n",
    "print(toxic_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rate of toxic comments in the dataset: \n",
      "0.09584448302009764\n"
     ]
    }
   ],
   "source": [
    "print(\"The rate of toxic comments in the dataset: \")\n",
    "print(toxic_data['toxic'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = toxic_data.comment_text.as_matrix()\n",
    "X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 131072)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "hv = HashingVectorizer(n_features= 2 ** 17, alternate_sign=False)\n",
    "# hv = HashingVectorizer(n_features= 2 ** 17, norm=None, non_negative=False)\n",
    "# hv = HashingVectorizer(n_features= + 1)\n",
    "# tv = TfidfVectorizer(features=2 ** 17, non_negative = True)\n",
    "# hv = HashingVectorizer(decode_error = 'ignore', n_features=2 ** 17, non_negative = True)\n",
    "# hv = HashingVectorizer(non_negative=True)\n",
    "# N_hv = HashingVectorizer(non_negative=True)\n",
    "X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_count  punc_count\n",
      "0          42           5\n",
      "1          18           2\n",
      "2          42           3\n",
      "3         112           3\n",
      "4          13           1\n",
      "5          12           1\n",
      "6           8           0\n",
      "7          21           2\n",
      "8          83           7\n",
      "9          12           0\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "\n",
    "\n",
    "X_quant_features = toxic_data[[\"word_count\", \"punc_count\"]]\n",
    "print(X_quant_features.head(10))\n",
    "print(type(X_quant_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 131074)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13080)\t-0.3352837541940735\n",
      "  (0, 20637)\t0.12273750000524668\n",
      "  (0, 24734)\t-0.05756850399552078\n",
      "  (0, 28641)\t0.30255698578348783\n",
      "  (0, 36157)\t-0.11300117557573076\n",
      "  (0, 38365)\t-0.2858310107057536\n",
      "  (0, 43099)\t0.06265026668613759\n",
      "  (0, 43902)\t-0.17992345892724868\n",
      "  (0, 45980)\t0.1435960247305051\n",
      "  (0, 46353)\t0.13568699421838595\n",
      "  (0, 49453)\t-0.1384992605089221\n",
      "  (0, 50743)\t-0.089351164688054\n",
      "  (0, 51619)\t0.11280487492095764\n",
      "  (0, 54542)\t-0.2221009321228698\n",
      "  (0, 61069)\t-0.41065661467663855\n",
      "  (0, 65396)\t-0.4538351025565183\n",
      "  (0, 67646)\t0.07583345070821097\n",
      "  (0, 69740)\t-0.11164777968958645\n",
      "  (0, 92259)\t0.2072488754885471\n",
      "  (0, 98369)\t0.1522711489306622\n",
      "  (0, 111869)\t0.21053732125232136\n",
      "  (0, 116871)\t-0.12394931615623446\n",
      "  (0, 131072)\t27.0\n"
     ]
    }
   ],
   "source": [
    "# look at an example of a \"row\" of a sparse matrix\n",
    "print(X_matrix[1234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 131074)\n"
     ]
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X = sc.fit_transform(X_matrix)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13080)\t-38.95725464549216\n",
      "  (0, 20637)\t3.349436911185673\n",
      "  (0, 24734)\t-0.8062888443587518\n",
      "  (0, 28641)\t31.74951192116682\n",
      "  (0, 36157)\t-2.5465838031790473\n",
      "  (0, 38365)\t-25.739199844475827\n",
      "  (0, 43099)\t1.1063300679196704\n",
      "  (0, 43902)\t-4.567234110131841\n",
      "  (0, 45980)\t2.023756518142615\n",
      "  (0, 46353)\t4.339484092685847\n",
      "  (0, 49453)\t-2.861090888355053\n",
      "  (0, 50743)\t-2.211898499002182\n",
      "  (0, 51619)\t2.6826550969136753\n",
      "  (0, 54542)\t-14.869262200434145\n",
      "  (0, 61069)\t-156.61578596302314\n",
      "  (0, 65396)\t-217.89132891482586\n",
      "  (0, 67646)\t1.466911611721104\n",
      "  (0, 69740)\t-3.340770670659583\n",
      "  (0, 92259)\t11.135702525315347\n",
      "  (0, 98369)\t4.93282853017257\n",
      "  (0, 111869)\t14.504120362070436\n",
      "  (0, 116871)\t-3.9167193534092553\n",
      "  (0, 131072)\t0.2686035598369133\n"
     ]
    }
   ],
   "source": [
    "# look at an example of a \"row\" of a sparse matrix, after scaling\n",
    "print(X[1234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656, 131074)\n",
      "(31915, 131074)\n",
      "(127656,)\n",
      "(31915,)\n",
      "(127656, 10)\n",
      "(31915, 10)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT, enter an integer into the variable below; any integer other than 74\n",
    "my_random_state = 666\n",
    "\n",
    "# create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# enter an integer for the random_state parameter; any integer will work\n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, toxic_data['toxic'], toxic_data, test_size= 0.2, random_state=my_random_state)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_raw_train.shape)\n",
    "print(X_raw_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12174.0, 'Neg': 141005.0, 'TP': 4899, 'TN': 45939, 'FP': 46436, 'FN': 4859, 'Accuracy': 0.3318862246130344, 'Precision': 0.09543196649459433, 'Recall': 0.4024149827501232, 'desc': 'ols_train'}\n"
     ]
    }
   ],
   "source": [
    "# ordinary least squares model\n",
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(ols_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12174.0, 'Neg': 141005.0, 'TP': 873, 'TN': 83530, 'FP': 8845, 'FN': 8885, 'Accuracy': 0.5510089503130324, 'Precision': 0.08983329903272279, 'Recall': 0.07171020206998521, 'desc': 'svm_train'}\n"
     ]
    }
   ],
   "source": [
    "# svm, linear model\n",
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12174.0, 'Neg': 141005.0, 'TP': 875, 'TN': 83537, 'FP': 8838, 'FN': 8883, 'Accuracy': 0.5510677051031799, 'Precision': 0.09008545248635849, 'Recall': 0.07187448661080992, 'desc': 'lgs_train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# logistical regression model (note: n_iter has been changed for max_iter)\n",
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log', max_iter=60, alpha=0.00001)\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(lgs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-8549047fa8ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnbs_performance_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationPerformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nbs_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mlabelbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m     \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "# naive bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X_train), y_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()\n",
    "print(nbs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
