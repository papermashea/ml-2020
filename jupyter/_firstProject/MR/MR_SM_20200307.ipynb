{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BinaryClassificationPerformance in module my_measures:\n",
      "\n",
      "class BinaryClassificationPerformance(builtins.object)\n",
      " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
      " |  \n",
      " |  Performance measures to evaluate the fit of a binary classification model, v1.02\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
      " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
      " |  \n",
      " |  compute_measures(self)\n",
      " |      Compute performance measures defined by Flach p. 57\n",
      " |  \n",
      " |  img_indices(self)\n",
      " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    movie_data = pd.read_csv(fn, sep='\\t')\n",
    "    print(\"movie_data is:\", type(movie_data))\n",
    "    print(\"movie_data has\", movie_data.shape[0], \"rows and\", movie_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in movie_data:\")\n",
    "    print(movie_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in movie_data:\")\n",
    "    print(movie_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'good' movie reviews in the dataset: \")\n",
    "        print(movie_data['sentiment'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "    X_hv = hv.fit_transform(movie_data.review)\n",
    "    print(\"Shape of HashingVectorizer X:\")\n",
    "    print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    transformer = TfidfTransformer()\n",
    "    X_tfidf = transformer.fit_transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    movie_data['word_count'] = movie_data['review'].str.split(' ').str.len()\n",
    "    movie_data['punc_count'] = movie_data['review'].str.count(\"\\.\")\n",
    "\n",
    "    X_quant_features = movie_data[[\"word_count\", \"punc_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    X = sc.fit_transform(X_matrix)\n",
    "    print(X.shape)\n",
    "    if (not test):\n",
    "        y = movie_data['sentiment']\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(movie_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, movie_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "movie_data has 25000 rows and 3 columns \n",
      "\n",
      "the data types for each of the columns in movie_data:\n",
      "id           object\n",
      "sentiment     int64\n",
      "review       object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in movie_data:\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
      "The rate of 'good' movie reviews in the dataset: \n",
      "0.5\n",
      "Shape of HashingVectorizer X:\n",
      "(25000, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0         433          20\n",
      "1         158          16\n",
      "2         378          20\n",
      "3         379           8\n",
      "4         367           9\n",
      "5          89           5\n",
      "6         112           9\n",
      "7         132           9\n",
      "8         163           7\n",
      "9          43           5\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(25000, 131074)\n",
      "(25000, 131074)\n",
      "Shape of X_train and X_test:\n",
      "(20000, 131074)\n",
      "(5000, 131074)\n",
      "Shape of y_train and y_test:\n",
      "(20000,)\n",
      "(5000,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(20000, 5)\n",
      "(5000, 5)\n",
      "SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='/Users/smolloy/Dev/parsons/ml-2020_data/moviereviews_train.tsv', my_random_seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10033, 'Neg': 9967, 'TP': 9603, 'TN': 9810, 'FP': 157, 'FN': 430, 'Accuracy': 0.97065, 'Precision': 0.9839139344262295, 'Recall': 0.9571414332702083, 'desc': 'nbs_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X_train), y_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()\n",
    "print(nbs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
